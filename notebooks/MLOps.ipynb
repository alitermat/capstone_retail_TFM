{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASO DE USO DE ABASTECIMIENTO DE TIENDAS (CON MLOps)\n",
    "\n",
    "## Fase 1: Prueba piloto y evaluación\n",
    "\n",
    "### 1.1 Diseño y preparación del piloto\n",
    "- **Selección estratégica de tiendas y productos:** Para probar la robustez de nuestro modelo XGBoost, elegimos tiendas de diferentes tamaños y ubicaciones en las ciudades de Philadelphia, Nueva York y Boston. Seleccionaremos una tienda grande en Nueva York, una tienda mediana en el distrito histórico de Philadelphia y una tienda pequeña en un barrio residencial de Boston. De cada categoría de productos (accesorios, supermercado y jardín), elegiremos productos de alta demanda (dentro de la categoría de accesorios), productos de demanda moderada (como los de supermercado) y productos de demanda estacional (como los de jardín).\n",
    "- **Definición de métricas de éxito:** Establecemos indicadores clave de rendimiento como el Error Absoluto Medio (MAE) para cuantificar la precisión del modelo y métricas operacionales como la reducción en desviaciones de inventario, proporcionando una visión holística del impacto del modelo en la eficiencia operativa.\n",
    "\n",
    "### 1.2 Implementación y configuración del entorno de pruebas\n",
    "- **Orquestación de contenedores con Kubernetes en AWS EC2:** Creamos un entorno de pruebas en AWS EC2 (Elastic Compute Cloud) utilizando Kubernetes, donde cada instancia actúa como un servidor virtual para una de las tiendas seleccionadas. Elegimos instancias como las de la familia T3 para un equilibrio entre costo y rendimiento (estas instancias son apropiadas para una variedad de cargas de trabajo y ofrecen un nivel de rendimiento adecuado a un precio razonable), asegurando que tengan suficiente capacidad para procesar los datos de ventas y ejecutar el modelo XGBoost. Kubernetes nos permite orquestar los contenedores de Docker, donde se alojan las instancias del modelo XGBoost.\n",
    "- **Pruebas de integración automatizadas:** Automatizamos pruebas de integración con GitHub Actions para simular llamadas API al sistema de punto de venta (POS) y al sistema de planificación de recursos empresariales (ERP) de cada tienda. Esto nos ayuda a probar cómo el modelo interactúa con los sistemas existentes, como enviar una solicitud de predicción de ventas para la próxima semana de un producto específico y recibir los datos pronosticados en respuesta.\n",
    "\n",
    "### 1.3 Ejecución del Piloto\n",
    "- **Despliegue consistente con Docker y Kubernetes:** Desplegamos el modelo XGBoost en contenedores Docker, lo que nos permite replicar el entorno de manera coherente en todas las instancias de EC2. Kubernetes nos permite escalar y gestionar la infraestructura subyacente de manera eficaz, independientemente de la tienda. El modelo funcionará de la misma manera, garantizando la consistencia en las pruebas.\n",
    "- **Dashboards de monitoreo en tiempo real:** Para visualizar el rendimiento del modelo, configuramos dashboards en Power BI que muestran métricas en tiempo real, como las ventas pronosticadas versus las ventas reales. Esto nos permite identificar rápidamente si hay alguna desviación significativa que necesite ser investigada y corregida.\n",
    "\n",
    "### 1.4 Análisis de Resultados y Retroalimentación\n",
    "- **Análisis detallado con Power BI:** Con MLflow, seguimos y registramos cada experimento, permitiendo un análisis más profundo de los resultados. Combinamos esta información con visualizaciones avanzadas en Power BI para comprender mejor el comportamiento del modelo y su impacto. Por ejemplo, podríamos descubrir que el modelo subestima las ventas de productos de jardinería durante un fin de semana soleado en Boston, lo cual nos indicaría la necesidad de ajustar cómo el modelo considera las variables climáticas.\n",
    "- **Captura de retroalimentación del personal:** Complementamos el análisis técnico con opiniones del personal de las tiendas mediante encuestas en línea. Esta retroalimentación nos proporciona información valiosa sobre cómo las predicciones afectan el proceso de abastecimiento y nos ayuda a mejorar la usabilidad y precisión de las predicciones para futuras iteraciones.\n",
    "\n",
    "## Fase 2: Despliegue y operacionalización\n",
    "\n",
    "### 2.1 Desarrollo de la API\n",
    "- **Definición clara de la API con OpenAPI:** Usamos OpenAPI para definir claramente los endpoints de la API, métodos HTTP, y la estructura de las solicitudes y respuestas. Esto proporciona una documentación clara y un contrato de interfaz para los desarrolladores. El código y la documentación se mantienen en un repositorio de GitHub, lo que facilita el control de versiones y la colaboración entre equipos.\n",
    "- **Construcción de API asincrónica con FastAPI:** Utilizando FastAPI, un framework moderno y rápido para construir APIs, desarrollamos una interfaz que permite a los sistemas de las tiendas interactuar con nuestro modelo de predicción. La API está diseñada para ser asincrónica, lo que significa que puede manejar múltiples solicitudes de predicción simultáneamente sin degradar el rendimiento, algo crucial durante los picos de demanda.\n",
    "\n",
    "### 2.2 Seguridad y Pruebas\n",
    "- **Autenticación robusta con JWT:** Implementamos tokens JWT (JSON Web Tokens) para asegurar que solo usuarios autorizados puedan acceder a las predicciones. Esto implica que cada solicitud a la API debe incluir un token válido en la cabecera de autorización.\n",
    "- **Suite de pruebas automatizadas:** Creamos un conjunto de pruebas automáticas con pytest para validar la funcionalidad de la API. Las pruebas se ejecutan automáticamente cada vez que se actualiza el código fuente en el repositorio de GitHub, a través de un pipeline de integración continua (CI) configurado en GitHub Actions.\n",
    "\n",
    "### 2.3 Despliegue y Monitoreo Continuo\n",
    "- **Automatización con CI/CD:** Configuramos un flujo de trabajo de integración y despliegue continuo (CI/CD) con GitHub Actions y Kubernetes. Esto nos permite automatizar las pruebas y el despliegue de la API en el entorno de producción de AWS ECS, asegurando implementaciones seguras y eficientes.\n",
    "- **Monitoreo proactivo con Power BI y GitHub:** Utilizamos Power BI para monitorear métricas operativas y establecemos alertas automatizadas con GitHub para mantenernos informados sobre la salud y el rendimiento de la API. Esto incluye métricas como la latencia, el número de solicitudes por segundo y los errores de servidor, lo\n",
    "\n",
    " que nos permite responder rápidamente ante cualquier disfunción operativa.\n",
    "\n",
    "### 2.4 Integración con sistemas de negocio\n",
    "- **Middleware eficaz con Apache Kafka:** Desplegamos Apache Kafka, gestionado por Kubernetes, como un sistema de mensajería para facilitar la transferencia de datos entre la API de predicción de ventas y los sistemas de producción de ventas(POS) y ERP de las tiendas. Esto asegura que los datos de ventas y las predicciones se sincronicen de manera confiable y en tiempo real.\n",
    "- **Automatización de procesos con Microsoft Power Automate:** Configuramos flujos de trabajo automatizados que aprovechan las predicciones generadas por nuestra API para optimizar el abastecimiento. Por ejemplo, si la API predice un aumento en la demanda de accesorios en una tienda de Nueva York, Power Automate puede iniciar automáticamente un proceso de reorden de inventario.\n",
    "\n",
    "### 2.5 Soporte Post-Despliegue\n",
    "- **Gestión de incidencias con Jira:** Establecemos un sistema de ticketing con Jira para que el personal de las tiendas pueda reportar cualquier problema técnico o inquietud relacionada con la API o las predicciones del modelo XGBoost. Esto nos permite rastrear, priorizar y resolver problemas de manera eficiente.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
