{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASO DE USO DE ABASTECIMIENTO DE TIENDAS (CON MLOps)\n",
    "\n",
    "## Fase 1: Prueba piloto y evaluación\n",
    "Esta fase es esencial para validar la viabilidad y efectividad del modelo en un entorno controlado antes de un despliegue a gran escala.\n",
    "### 1.1 Diseño y preparación del piloto\n",
    "Es el primer paso natural donde se seleccionan las tiendas y se definen las métricas de éxito. Establecer estas bases es crucial antes de comenzar cualquier implementación técnica.\n",
    "- **Selección estratégica de tiendas y productos:** Para probar la robustez de nuestro modelo XGBoost, elegimos tiendas de diferentes tamaños y ubicaciones en las ciudades de Philadelphia, Nueva York y Boston. Seleccionamos una tienda grande en Nueva York, una tienda mediana en el distrito histórico de Philadelphia y una tienda pequeña en un barrio residencial de Boston. De cada categoría de productos (accesorios, supermercado y jardín), elegiremos productos de alta demanda (dentro de la categoría de accesorios), productos de demanda moderada (como los de supermercado) y productos de demanda estacional (como los de jardín).\n",
    "- **Definición de métricas de éxito:** Definimos meticulosamente indicadores clave de desempeño (KPIs) que nos permiten medir la efectividad de nuestro modelo con precisión y relevancia operacional. Entre estos, destacamos el Error Absoluto Medio (MAE) para evaluar la exactitud de las predicciones realizadas por el modelo. Además, incorporamos métricas centradas en la operatividad, como la disminución en las discrepancias de inventario, lo cual nos brinda una comprensión integral del valor agregado del modelo a la eficiencia y optimización de las operaciones comerciales. Estos indicadores son cruciales para monitorear el rendimiento y guiar las mejoras continuas del sistema predictivo.\n",
    "\n",
    "### 1.2 Implementación y configuración del entorno de pruebas\n",
    "Una vez que se han establecido los objetivos y se ha realizado la selección estratégica, el siguiente paso es configurar el entorno donde se llevará a cabo la prueba piloto.\n",
    "- **Orquestación de contenedores con Kubernetes en AWS EC2:** Creamos un entorno de pruebas en AWS EC2 (Elastic Compute Cloud) utilizando Kubernetes, donde cada instancia actúa como un servidor virtual para cada una de las tiendas seleccionadas. Elegimos instancias como las de la familia T3 para un equilibrio entre costo y rendimiento (estas instancias son apropiadas para una variedad de cargas de trabajo y ofrecen un nivel de rendimiento adecuado a un precio razonable), asegurando que tengan suficiente capacidad para procesar los datos de ventas y ejecutar el modelo XGBoost. Kubernetes nos permite orquestar los contenedores de Docker, donde se alojan las instancias del modelo XGBoost.\n",
    "- **Pruebas de integración automatizadas:** Automatizamos pruebas de integración con GitHub Actions para simular llamadas API al sistema de punto de venta (POS) y al sistema de planificación de recursos empresariales (ERP) de cada tienda. Esto nos ayuda a probar cómo el modelo interactúa con los sistemas existentes, como enviar una solicitud de predicción de ventas para la próxima semana de un producto específico y recibir los datos pronosticados en respuesta.\n",
    "\n",
    "### 1.3 Ejecución del piloto\n",
    "Con el entorno listo, se procede a ejecutar la prueba piloto y a monitorear su desempeño a través de dashboards y otras herramientas de seguimiento.\n",
    "- **Despliegue consistente con Docker y Kubernetes:** Desplegamos el modelo XGBoost en contenedores Docker, lo que nos permite replicar el entorno de manera coherente en todas las instancias de EC2. Kubernetes nos permite escalar y gestionar la infraestructura subyacente de manera eficaz, independientemente de la tienda. El modelo funcionará de la misma manera, garantizando la consistencia en las pruebas.\n",
    "- **Dashboards de monitoreo de batch diario:** Para analizar el rendimiento del modelo de forma periódica, configuramos dashboards en Power BI que actualizan y muestran métricas clave una vez al día, como las ventas pronosticadas frente a las ventas reales del día anterior. Esto facilita el seguimiento de tendencias y patrones día a día, permitiéndonos detectar y abordar desviaciones o ineficiencias de forma oportuna en un ciclo de revisión diario.\n",
    "\n",
    "### 1.4 Análisis de resultados y retroalimentación\n",
    "Finalmente, se analizan los resultados y se recopila la retroalimentación para afinar y mejorar el modelo antes del despliegue a gran escala.\n",
    "- **Análisis detallado con Power BI:** Con MLflow, seguimos y registramos cada experimento, permitiendo un análisis más profundo de los resultados. Combinamos esta información con visualizaciones avanzadas en Power BI para comprender mejor el comportamiento del modelo y su impacto. Por ejemplo, podríamos descubrir que el modelo subestima las ventas de productos de jardinería durante un fin de semana soleado en Boston, lo cual nos indicaría la necesidad de ajustar cómo el modelo considera las variables climáticas.\n",
    "- **Captura de retroalimentación del personal:** Complementamos el análisis técnico con opiniones del personal de las tiendas mediante encuestas en línea. Esta retroalimentación nos proporciona información valiosa sobre cómo las predicciones afectan el proceso de abastecimiento y nos ayuda a mejorar la usabilidad y precisión de las predicciones para futuras iteraciones.\n",
    "\n",
    "## Fase 2: Despliegue y operacionalización\n",
    "Una vez que la prueba piloto ha sido exitosa y se han realizado las mejoras necesarias, se procede a la fase de despliegue y operacionalización.\n",
    "### 2.1 Desarrollo de la API\n",
    "Desarrollar la API es un paso previo al despliegue ya que será el punto de integración entre el modelo y los sistemas existentes.\n",
    "- **Definición clara de la API con OpenAPI:** Usamos OpenAPI para definir claramente los endpoints de la API, métodos HTTP, y la estructura de las solicitudes y respuestas. Esto proporciona una documentación clara y un contrato de interfaz para los desarrolladores. El código y la documentación se mantienen en un repositorio de GitHub, lo que facilita el control de versiones y la colaboración entre equipos.\n",
    "- **Implementación de una API asincrónica con FastAPI:** Con FastAPI, que es un framework avanzado y eficiente diseñado para la construcción de APIs web en Python, implentaremos una API asincrónica que se integra perfectamente con nuestro modelo predictivo. FastAPI facilita la creación de interfaces con claridad y precisión, gracias a su soporte nativo para asincronismo y su enfoque en la velocidad y la facilidad de desarrollo. La API se construye definiendo rutas operativas, modelos de solicitud y respuesta con Pydantic para la validación de datos, y utilizando las capacidades asincrónicas de Python para manejar múltiples solicitudes de manera concurrente. Este diseño permite a los sistemas de las tiendas enviar solicitudes de predicción que se procesan de forma no bloqueante, asegurando un servicio rápido y confiable incluso durante picos de tráfico intenso.\n",
    "\n",
    "### 2.2 Seguridad y Pruebas\n",
    "La seguridad es fundamental antes de poner la API a disposición de los usuarios, y las pruebas automatizadas aseguran que la API funciona como se espera.\n",
    "- **Autenticación robusta con JWT:** Implementamos tokens JWT (JSON Web Tokens) para asegurar que solo usuarios autorizados puedan acceder a las predicciones. Esto implica que cada solicitud a la API debe incluir un token válido en la cabecera de autorización.\n",
    "- **Suite de pruebas automatizadas:** Creamos un conjunto de pruebas automáticas con pytest para validar la funcionalidad de la API. Las pruebas se ejecutan automáticamente cada vez que se actualiza el código fuente en el repositorio de GitHub, a través de un pipeline de integración continua (CI) configurado en GitHub Actions.\n",
    "\n",
    "### 2.3 Despliegue y monitoreo continuo\n",
    "Con la API probada y segura, se procede a su despliegue en producción, asegurándose de que haya un monitoreo continuo para detectar y resolver problemas rápidamente.\n",
    "- **Automatización con CI/CD:** Configuramos un flujo de trabajo de integración y despliegue continuo (CI/CD) con GitHub Actions y Kubernetes. Esto nos permite automatizar las pruebas y el despliegue de la API en el entorno de producción de AWS ECS, asegurando implementaciones seguras y eficientes.\n",
    "- **Monitoreo proactivo con Power BI y GitHub:** Utilizamos Power BI para monitorear métricas operativas y establecemos alertas automatizadas con GitHub para mantenernos informados sobre la salud y el rendimiento de la API. Esto incluye métricas como la latencia, el número de solicitudes por segundo y los errores de servidor, lo que nos permite responder rápidamente ante cualquier disfunción operativa.\n",
    "\n",
    "### 2.4 Integración con sistemas de negocio\n",
    "La integración efectiva con los sistemas existentes es crucial para que el modelo aporte valor en un contexto de negocio real.\n",
    "- **Middleware eficaz con Apache Kafka:** Desplegamos Apache Kafka, gestionado por Kubernetes, como un sistema de mensajería para facilitar la transferencia de datos entre la API de predicción de ventas y los sistemas de producción de ventas(POS) y ERP de las tiendas. Esto asegura que los datos de ventas y las predicciones se sincronicen de manera confiable y en tiempo real.\n",
    "- **Automatización de procesos con Microsoft Power Automate:** Configuramos flujos de trabajo automatizados que aprovechan las predicciones generadas por nuestra API para optimizar el abastecimiento. Por ejemplo, si la API predice un aumento en la demanda de accesorios en una tienda de Nueva York, Power Automate puede iniciar automáticamente un proceso de reorden de inventario.\n",
    "\n",
    "### 2.5 Soporte Post-Despliegue\n",
    "Finalmente, se establece un sistema de soporte para atender cualquier incidencia o necesidad de mantenimiento que surja tras el despliegue.\n",
    "- **Gestión de incidencias con Jira:** Establecemos un sistema de ticketing con Jira para que el personal de las tiendas pueda reportar cualquier problema técnico o inquietud relacionada con la API o las predicciones del modelo XGBoost. Esto nos permite rastrear, priorizar y resolver problemas de manera eficiente."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
