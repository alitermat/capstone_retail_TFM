{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASO DE USO DE ABASTECIMIENTO DE TIENDAS (CON MLOps)\n",
    "\n",
    "## Fase 1: Prueba piloto y evaluación\n",
    "Esta fase es esencial para validar la viabilidad y efectividad del modelo en un entorno controlado antes de un despliegue a gran escala.\n",
    "### 1.1. Diseño y preparación del piloto\n",
    "Es el primer paso natural donde se seleccionan las tiendas y se definen las métricas de éxito. Establecer estas bases es crucial antes de comenzar cualquier implementación técnica.\n",
    "- **Selección estratégica de tiendas y productos:** Para probar la robustez de nuestro modelo CatBoost, elegimos tiendas de diferentes tamaños y ubicaciones en las ciudades de Philadelphia, Nueva York y Boston. Seleccionamos una tienda grande en Nueva York, una tienda mediana en el distrito histórico de Philadelphia y una tienda pequeña en un barrio residencial de Boston. De cada categoría de productos (accesorios, supermercado y jardín), elegiremos productos de alta demanda (dentro de la categoría de accesorios), productos de demanda moderada (como los de supermercado) y productos de demanda estacional (como los de jardín).\n",
    "- **Definición de métricas de éxito:** Definimos meticulosamente indicadores clave de desempeño (KPIs) que nos permiten medir la efectividad de nuestro modelo con precisión y relevancia operacional. Entre estos, destacamos el Error Absoluto Medio (MAE) para evaluar la exactitud de las predicciones realizadas por el modelo. Además, incorporamos métricas centradas en la operatividad, como la disminución en las discrepancias de inventario, lo cual nos brinda una comprensión integral del valor agregado del modelo a la eficiencia y optimización de las operaciones comerciales. Estos indicadores son cruciales para monitorear el rendimiento y guiar las mejoras continuas del sistema predictivo.\n",
    "### 1.2. Implementación y configuración del entorno de pruebas\n",
    "Una vez que se han establecido los objetivos y se ha realizado la selección estratégica, el siguiente paso es configurar el entorno donde se llevará a cabo la prueba piloto.\n",
    "- **Orquestación de contenedores con Kubernetes en AWS EC2:** Creamos un entorno de pruebas en AWS EC2 (Elastic Compute Cloud) utilizando Kubernetes, donde cada instancia actúa como un servidor virtual para cada una de las tiendas seleccionadas. Elegimos instancias como las de la familia T3 para un equilibrio entre costo y rendimiento (estas instancias son apropiadas para una variedad de cargas de trabajo y ofrecen un nivel de rendimiento adecuado a un precio razonable), asegurando que tengan suficiente capacidad para procesar los datos de ventas y ejecutar el modelo CatBoost. Kubernetes nos permite orquestar los contenedores de Docker, donde se alojan las instancias del modelo CatBoost.\n",
    "- **Pruebas de integración automatizadas:** Automatizamos pruebas de integración con GitHub Actions para simular llamadas API al sistema de punto de venta (POS) y al sistema de planificación de recursos empresariales (ERP) de cada tienda. Esto nos ayuda a probar cómo el modelo interactúa con los sistemas existentes, como enviar una solicitud de predicción de ventas para la próxima semana de un producto específico y recibir los datos pronosticados en respuesta.\n",
    "### 1.3. Ejecución del piloto\n",
    "Con el entorno listo, se procede a ejecutar la prueba piloto y a monitorear su desempeño a través de dashboards y otras herramientas de seguimiento.\n",
    "- **Despliegue consistente con Docker y Kubernetes:** Desplegamos el modelo CatBoost en contenedores Docker, lo que nos permite replicar el entorno de manera coherente en todas las instancias de EC2. Kubernetes nos permite escalar y gestionar la infraestructura subyacente de manera eficaz, independientemente de la tienda. El modelo funcionará de la misma manera, garantizando la consistencia en las pruebas.\n",
    "- **Dashboards de monitoreo de batch diario:** Para analizar el rendimiento del modelo de forma periódica, configuramos dashboards en Power BI que actualizan y muestran métricas clave una vez al día, como las ventas pronosticadas frente a las ventas reales del día anterior. Esto facilita el seguimiento de tendencias y patrones día a día, permitiéndonos detectar y abordar desviaciones o ineficiencias de forma oportuna en un ciclo de revisión diario.\n",
    "### 1.4. Análisis de resultados y retroalimentación\n",
    "Finalmente, se analizan los resultados y se recopila la retroalimentación para afinar y mejorar el modelo antes del despliegue a gran escala.\n",
    "- **Análisis detallado con Power BI:** Con MLflow, seguimos y registramos cada experimento, permitiendo un análisis más profundo de los resultados. Combinamos esta información con visualizaciones avanzadas en Power BI para comprender mejor el comportamiento del modelo y su impacto. Por ejemplo, podríamos descubrir que el modelo subestima las ventas de productos de jardinería durante un fin de semana soleado en Boston, lo cual nos indicaría la necesidad de ajustar cómo el modelo considera las variables climáticas.\n",
    "- **Captura de retroalimentación del personal:** Complementamos el análisis técnico con opiniones del personal de las tiendas mediante encuestas en línea. Esta retroalimentación nos proporciona información valiosa sobre cómo las predicciones afectan el proceso de abastecimiento y nos ayuda a mejorar la usabilidad y precisión de las predicciones para futuras iteraciones.\n",
    "\n",
    "## Fase 2: Despliegue y operacionalización\n",
    "Una vez que la prueba piloto ha sido exitosa y se han realizado las mejoras necesarias, se procede a la fase de despliegue y operacionalización.\n",
    "### 2.1. Desarrollo de la API\n",
    "Desarrollar la API es un paso previo al despliegue ya que será el punto de integración entre el modelo y los sistemas existentes.\n",
    "- **Definición clara de la API con OpenAPI:** Usamos OpenAPI para definir claramente los endpoints de la API, métodos HTTP, y la estructura de las solicitudes y respuestas. Esto proporciona una documentación clara y un contrato de interfaz para los desarrolladores. El código y la documentación se mantienen en un repositorio de GitHub, lo que facilita el control de versiones y la colaboración entre equipos.\n",
    "- **Implementación de una API asincrónica con FastAPI:** Con FastAPI, que es un framework avanzado y eficiente diseñado para la construcción de APIs web en Python, implentaremos una API asincrónica que se integra perfectamente con nuestro modelo predictivo. FastAPI facilita la creación de interfaces con claridad y precisión, gracias a su soporte nativo para asincronismo y su enfoque en la velocidad y la facilidad de desarrollo. La API se construye definiendo rutas operativas, modelos de solicitud y respuesta con Pydantic para la validación de datos, y utilizando las capacidades asincrónicas de Python para manejar múltiples solicitudes de manera concurrente. Este diseño permite a los sistemas de las tiendas enviar solicitudes de predicción que se procesan de forma no bloqueante, asegurando un servicio rápido y confiable incluso durante picos de tráfico intenso.\n",
    "### 2.2. Seguridad y Pruebas\n",
    "La seguridad es fundamental antes de poner la API a disposición de los usuarios, y las pruebas automatizadas aseguran que la API funciona como se espera.\n",
    "- **Autenticación robusta con JWT:** Implementamos tokens JWT (JSON Web Tokens) para asegurar que solo usuarios autorizados puedan acceder a las predicciones. Esto implica que cada solicitud a la API debe incluir un token válido en la cabecera de autorización.\n",
    "- **Suite de pruebas automatizadas:** Creamos un conjunto de pruebas automáticas con pytest para validar la funcionalidad de la API. Las pruebas se ejecutan automáticamente cada vez que se actualiza el código fuente en el repositorio de GitHub, a través de un pipeline de integración continua (CI) configurado en GitHub Actions.\n",
    "### 2.3. Despliegue y monitoreo continuo\n",
    "Con la API probada y segura, se procede a su despliegue en producción, asegurándose de que haya un monitoreo continuo para detectar y resolver problemas rápidamente.\n",
    "- **Automatización con CI/CD:** Configuramos un flujo de trabajo de integración y despliegue continuo (CI/CD) con GitHub Actions y Kubernetes. Esto nos permite automatizar las pruebas y el despliegue de la API en el entorno de producción de AWS ECS, asegurando implementaciones seguras y eficientes.\n",
    "- **Monitoreo proactivo con Power BI y GitHub:** Utilizamos Power BI para monitorear métricas operativas y establecemos alertas automatizadas con GitHub para mantenernos informados sobre la salud y el rendimiento de la API. Esto incluye métricas como la latencia, el número de solicitudes por segundo y los errores de servidor, lo que nos permite responder rápidamente ante cualquier disfunción operativa.\n",
    "### 2.4. Integración con sistemas de negocio\n",
    "La integración efectiva con los sistemas existentes es crucial para que el modelo aporte valor en un contexto de negocio real.\n",
    "- **Middleware eficaz con Apache Kafka:** Desplegamos Apache Kafka, gestionado por Kubernetes, como un sistema de mensajería para facilitar la transferencia de datos entre la API de predicción de ventas y los sistemas de producción de ventas (POS) y ERP de las tiendas. Esto asegura que los datos de ventas y las predicciones se sincronicen de manera confiable y en tiempo real.\n",
    "- **Automatización de procesos con Microsoft Power Automate:** Configuramos flujos de trabajo automatizados que aprovechan las predicciones generadas por nuestra API para optimizar el abastecimiento. Por ejemplo, si la API predice un aumento en la demanda de accesorios en una tienda de Nueva York, Power Automate puede iniciar automáticamente un proceso de reorden de inventario.\n",
    "### 2.5. Soporte Post-Despliegue\n",
    "Finalmente, se establece un sistema de soporte para atender cualquier incidencia o necesidad de mantenimiento que surja tras el despliegue.\n",
    "- **Gestión de incidencias con Jira:** Establecemos un sistema de ticketing con Jira para que el personal de las tiendas pueda reportar cualquier problema técnico o inquietud relacionada con la API o las predicciones del modelo CatBoost. Esto nos permite rastrear, priorizar y resolver problemas de manera eficiente.\n",
    "\n",
    "## Fase 3: Monitorización del modelo\n",
    "Como con cualquier otro proceso de software implementado en producción, es fundamental monitorear los modelos de Machine Learning para garantizar su correcta ejecución y el uso eficiente de los recursos computacionales. Además del monitoreo de infraestructura y la integración de sistemas de negocio que ya hemos visto en la fase dos, los modelos de Machine Learning requieren una vigilancia especial para evaluar su rendimiento y calidad como predictores, especialmente porque los modelos pueden perder precisión a medida que los datos de entrada difieren progresivamente de los utilizados durante el entrenamiento.\n",
    "- **MLflow para el seguimiento del rendimiento del modelo:** MLflow se utiliza para registrar métricas de rendimiento y parámetros del modelo en producción. Estos datos nos permiten evaluar la precisión del modelo a lo largo del tiempo y detectar cualquier señal de deriva de datos o degradación en el rendimiento del modelo. MLflow ofrece una interfaz centralizada para comparar estas métricas a lo largo de diferentes versiones del modelo, facilitando la identificación de cuándo podría ser necesario reentrenar o ajustar el modelo.\n",
    "- **Detección de deriva de datos (Data Drift) con MLflow:** A través de MLflow, monitorizamos las distribuciones de las características de entrada y las comparamos con los datos de entrenamiento original. MLflow puede ayudar a detectar cambios en los patrones de los datos que podrían afectar el rendimiento del modelo. Al detectar estos cambios, podemos ser proactivos en el reentrenamiento del modelo o en la toma de decisiones para mantener su relevancia y precisión.\n",
    "- **Kubernetes para la monitorización operativa:** Continuamos usando Kubernetes para supervisar el estado y la salud de los contenedores donde se ejecutan los modelos. Kubernetes nos brinda herramientas para el monitoreo de recursos, como el uso de CPU y memoria, y para la gestión de logs. Los registros generados por los modelos se recopilan y se analizan para identificar posibles excepciones o fallas en la ejecución del modelo, proporcionando una capa adicional de transparencia y trazabilidad.\n",
    "\n",
    "Al integrar MLflow con Kubernetes, proporcionamos un sistema comprensivo para la monitorización del modelo que no solo se centra en los aspectos operativos, sino también en la calidad y rendimiento del modelo en sí. Esta combinación de herramientas nos permite mantener la confiabilidad del sistema de abastecimiento y asegurar que las decisiones basadas en los modelos de Machine Learning se tomen con datos y predicciones que se mantienen precisas y actualizadas.\n",
    "\n",
    "## Fase 4: Reentrenamiento o sustitución de modelo\n",
    "La monitorización continua y el análisis de la Fase 3 pueden revelar la necesidad de actualizar o ajustar el modelo para mantener o mejorar su precisión y relevancia. Esta fase se centra en la acción proactiva de mantener los modelos alineados con las últimas tendencias de los datos y las necesidades del negocio.\n",
    "- **Evaluación y decisión de reentrenamiento:** A partir de los insights obtenidos con MLflow, tomamos la decisión de reentrenar o refinar el modelo. Esta decisión se basa en métricas de rendimiento, la detección de deriva de datos y el feedback operativo capturado durante la monitorización. La decisión también tiene en cuenta el impacto operacional y comercial de mantener el modelo actual frente a los beneficios de actualizarlo.\n",
    "- **Gestión del ciclo de vida de modelos con MLflow:** Cuando se decide que el modelo necesita ser reentrenado, MLflow es fundamental para gestionar el ciclo de vida del modelo. Aquí, MLflow proporciona las herramientas para versionar el modelo, registrar los conjuntos de datos de reentrenamiento, y rastrear el rendimiento de las nuevas versiones. Cada iteración y experimento se registra meticulosamente para asegurar que los ajustes resulten en mejoras tangibles.\n",
    "- **Pruebas y validación rigurosas:** Antes de que cualquier modelo actualizado llegue a producción, se somete a un proceso de pruebas rigurosas. Utilizamos conjuntos de datos de validación y pruebas para asegurarnos de que el modelo reentrenado no solo se ajusta a los datos históricos, sino que también generaliza bien a nuevas situaciones, manteniendo su robustez y capacidad predictiva.\n",
    "- **Implementación suave y rollback:** Con MLflow y las capacidades de orquestación de contenedores de Kubernetes, podemos implementar nuevas versiones del modelo de manera controlada y con estrategias de despliegue que minimizan el riesgo, como Blue/Green deployment(técnica que utiliza dos entornos de producción paralelos para garantizar una transición sin interrupciones) o Canary releases(despliegan una nueva versión a una audiencia limitada para probar su rendimiento antes de su liberación completa). Además, si se detectan problemas después del despliegue, podemos revertir rápidamente a la versión anterior del modelo.\n",
    "- **Ciclo de retroalimentación continua:** Una vez que el modelo actualizado está en producción, el ciclo de MLOps vuelve a la Fase 2 para operacionalización y monitoreo. De esta manera, nos aseguramos de que el modelo sigue siendo relevante y efectivo, y que cualquier aprendizaje o mejora se incorpora rápidamente en el ciclo de vida del modelo.\n",
    "\n",
    "Esta fase final cierra el ciclo de MLOps, subrayando la naturaleza iterativa y continua del despliegue y mantenimiento de modelos de Machine Learning en producción. Con un enfoque sistemático y herramientas como MLflow y Kubernetes, nos aseguramos de que nuestros modelos de predicción están siempre actualizados, son precisos y brindan el máximo valor a las operaciones de abastecimiento de tiendas."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
